{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install necessary libraries","metadata":{}},{"cell_type":"code","source":"%%capture\n\n!pip install datasets\n!pip install sentence-transformers\n!pip install transformers","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-06-02T13:48:39.698798Z","iopub.execute_input":"2023-06-02T13:48:39.699466Z","iopub.status.idle":"2023-06-02T13:49:17.495375Z","shell.execute_reply.started":"2023-06-02T13:48:39.699428Z","shell.execute_reply":"2023-06-02T13:49:17.494114Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sentence_transformers import SentenceTransformer, models\nfrom transformers import BertTokenizer\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2023-06-02T13:49:22.970526Z","iopub.execute_input":"2023-06-02T13:49:22.970983Z","iopub.status.idle":"2023-06-02T13:49:28.806838Z","shell.execute_reply.started":"2023-06-02T13:49:22.970945Z","shell.execute_reply":"2023-06-02T13:49:28.805902Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Fetch data for training and test, as well as the tokenizer","metadata":{}},{"cell_type":"code","source":"# Dataset for training\ndataset = load_dataset(\"stsb_multi_mt\", name=\"en\", split=\"train\")\nsimilarity = [i['similarity_score'] for i in dataset]\nnormalized_similarity = [i/5.0 for i in similarity]\n\n# Dataset for test\ntest_dataset = load_dataset(\"stsb_multi_mt\", name=\"en\", split=\"test\")\n\n# Prepare test data\nsentence_1_test = [i['sentence1'] for i in test_dataset]\nsentence_2_test = [i['sentence2'] for i in test_dataset]\ntext_cat_test = [[str(x), str(y)] for x,y in zip(sentence_1_test, sentence_2_test)]\n\n# Set the tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T13:49:33.931849Z","iopub.execute_input":"2023-06-02T13:49:33.932625Z","iopub.status.idle":"2023-06-02T13:49:42.951784Z","shell.execute_reply.started":"2023-06-02T13:49:33.932588Z","shell.execute_reply":"2023-06-02T13:49:42.950810Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b380bd0cf84d4612a2334e21d554df09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fbe90c630cf464e8b4541e4de18da75"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset stsb_multi_mt/en (download: 1.02 MiB, generated: 1.06 MiB, post-processed: Unknown size, total: 2.08 MiB) to /root/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d3f4c1974634e6ea40d1a6561d4b9e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/229k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a247b6c155f74af9ac2f6f420279b98a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/74.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feb939be49d74d34b828d57802e33a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/52.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"779a83e241aa450ba5331521c64c2c65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset stsb_multi_mt downloaded and prepared to /root/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4486b7194ba040928cbcb46b3b19a38d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3c2daac47cd4e8eb310879e2d2ce3a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c538c4c9ec6f4353862828da0e3dacef"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Define Model architecture","metadata":{}},{"cell_type":"code","source":"class STSBertModel(torch.nn.Module):\n\n    def __init__(self):\n\n        super(STSBertModel, self).__init__()\n\n        word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=128)\n        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n        self.sts_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n\n    def forward(self, input_data):\n\n        output = self.sts_model(input_data)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2023-06-02T13:49:48.775784Z","iopub.execute_input":"2023-06-02T13:49:48.776137Z","iopub.status.idle":"2023-06-02T13:49:48.783005Z","shell.execute_reply.started":"2023-06-02T13:49:48.776110Z","shell.execute_reply":"2023-06-02T13:49:48.782012Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Define Dataloader for training","metadata":{}},{"cell_type":"code","source":"class DataSequence(torch.utils.data.Dataset):\n\n    def __init__(self, dataset):\n\n        similarity = [i['similarity_score'] for i in dataset]\n        self.label = [i/5.0 for i in similarity]\n        self.sentence_1 = [i['sentence1'] for i in dataset]\n        self.sentence_2 = [i['sentence2'] for i in dataset]\n        self.text_cat = [[str(x), str(y)] for x,y in zip(self.sentence_1, self.sentence_2)]\n\n    def __len__(self):\n\n        return len(self.text_cat)\n\n    def get_batch_labels(self, idx):\n\n        return torch.tensor(self.label[idx])\n\n    def get_batch_texts(self, idx):\n\n        return tokenizer(self.text_cat[idx], padding='max_length', max_length = 128, truncation=True, return_tensors=\"pt\")\n\n    def __getitem__(self, idx):\n\n        batch_texts = self.get_batch_texts(idx)\n        batch_y = self.get_batch_labels(idx)\n\n        return batch_texts, batch_y\n\ndef collate_fn(texts):\n\n  num_texts = len(texts['input_ids'])\n  features = list()\n  for i in range(num_texts):\n      features.append({'input_ids':texts['input_ids'][i], 'attention_mask':texts['attention_mask'][i]})\n  \n  return features","metadata":{"execution":{"iopub.status.busy":"2023-06-02T13:49:55.271132Z","iopub.execute_input":"2023-06-02T13:49:55.271477Z","iopub.status.idle":"2023-06-02T13:49:55.283332Z","shell.execute_reply.started":"2023-06-02T13:49:55.271451Z","shell.execute_reply":"2023-06-02T13:49:55.282172Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Define loss function for training","metadata":{}},{"cell_type":"code","source":"class CosineSimilarityLoss(torch.nn.Module):\n\n    def __init__(self,  loss_fct = torch.nn.MSELoss(), cos_score_transformation=torch.nn.Identity()):\n      \n        super(CosineSimilarityLoss, self).__init__()\n        self.loss_fct = loss_fct\n        self.cos_score_transformation = cos_score_transformation\n        self.cos = torch.nn.CosineSimilarity(dim=1)\n\n    def forward(self, input, label):\n\n        embedding_1 = torch.stack([inp[0] for inp in input])\n        embedding_2 = torch.stack([inp[1] for inp in input])\n\n        output = self.cos_score_transformation(self.cos(embedding_1, embedding_2))\n\n        return self.loss_fct(output, label.squeeze())","metadata":{"execution":{"iopub.status.busy":"2023-06-02T13:50:00.360104Z","iopub.execute_input":"2023-06-02T13:50:00.360585Z","iopub.status.idle":"2023-06-02T13:50:00.370705Z","shell.execute_reply.started":"2023-06-02T13:50:00.360554Z","shell.execute_reply":"2023-06-02T13:50:00.369588Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"def model_train(dataset, epochs, learning_rate, bs):\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    model = STSBertModel()\n\n    criterion = CosineSimilarityLoss()\n    optimizer = Adam(model.parameters(), lr=learning_rate)\n\n    train_dataset = DataSequence(dataset)\n    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=bs, shuffle=True)\n\n    if use_cuda:\n        model = model.cuda()\n        criterion = criterion.cuda()\n\n    best_acc = 0.0\n    best_loss = 1000\n\n    for i in range(epochs):\n\n        total_acc_train = 0\n        total_loss_train = 0.0\n\n        for train_data, train_label in tqdm(train_dataloader):\n\n            train_data['input_ids'] = train_data['input_ids'].to(device)\n            train_data['attention_mask'] = train_data['attention_mask'].to(device)\n            del train_data['token_type_ids']\n\n            train_data = collate_fn(train_data)\n\n            output = [model(feature)['sentence_embedding'] for feature in train_data]\n\n            loss = criterion(output, train_label.to(device))\n            total_loss_train += loss.item()\n\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n        print(f'Epochs: {i + 1} | Loss: {total_loss_train / len(dataset): .3f}')\n        model.train()\n\n    return model\n\nEPOCHS = 8\nLEARNING_RATE = 1e-6\nBATCH_SIZE = 8\n\n# Train the model\ntrained_model = model_train(dataset, EPOCHS, LEARNING_RATE, BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T13:50:05.130435Z","iopub.execute_input":"2023-06-02T13:50:05.130842Z","iopub.status.idle":"2023-06-02T14:19:43.227204Z","shell.execute_reply.started":"2023-06-02T13:50:05.130812Z","shell.execute_reply":"2023-06-02T14:19:43.226106Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8571b301232842e6913400969aa51116"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d6e0020201346738b9dd92f349e31c1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n100%|██████████| 719/719 [03:34<00:00,  3.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 1 | Loss:  0.009\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:38<00:00,  3.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 2 | Loss:  0.004\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:39<00:00,  3.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 3 | Loss:  0.004\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:38<00:00,  3.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 4 | Loss:  0.003\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:38<00:00,  3.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 5 | Loss:  0.003\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:39<00:00,  3.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 6 | Loss:  0.003\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:38<00:00,  3.28it/s]","output_type":"stream"},{"name":"stdout","text":"Epochs: 8 | Loss:  0.002\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to predict test data\ndef predict_sts(texts):\n\n  trained_model.to('cpu')\n  trained_model.eval()\n  test_input = tokenizer(texts, padding='max_length', max_length = 128, truncation=True, return_tensors=\"pt\")\n  test_input['input_ids'] = test_input['input_ids']\n  test_input['attention_mask'] = test_input['attention_mask']\n  del test_input['token_type_ids']\n\n  test_output = trained_model(test_input)['sentence_embedding']\n  sim = torch.nn.functional.cosine_similarity(test_output[0], test_output[1], dim=0).item()\n\n  return sim","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:20:17.550175Z","iopub.execute_input":"2023-06-02T14:20:17.550554Z","iopub.status.idle":"2023-06-02T14:20:17.557961Z","shell.execute_reply.started":"2023-06-02T14:20:17.550521Z","shell.execute_reply":"2023-06-02T14:20:17.557020Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Predict on test data","metadata":{}},{"cell_type":"code","source":"predict_sts(text_cat_test[245])","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:20:21.514311Z","iopub.execute_input":"2023-06-02T14:20:21.515006Z","iopub.status.idle":"2023-06-02T14:20:22.507315Z","shell.execute_reply.started":"2023-06-02T14:20:21.514972Z","shell.execute_reply":"2023-06-02T14:20:22.506188Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0.05516544729471207"},"metadata":{}}]},{"cell_type":"code","source":"predict_sts(text_cat_test[420])","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:20:28.375748Z","iopub.execute_input":"2023-06-02T14:20:28.376695Z","iopub.status.idle":"2023-06-02T14:20:28.949469Z","shell.execute_reply.started":"2023-06-02T14:20:28.376637Z","shell.execute_reply":"2023-06-02T14:20:28.948376Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0.8704825043678284"},"metadata":{}}]},{"cell_type":"code","source":"text_cat_test[420]","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:20:44.920151Z","iopub.execute_input":"2023-06-02T14:20:44.920512Z","iopub.status.idle":"2023-06-02T14:20:44.927905Z","shell.execute_reply.started":"2023-06-02T14:20:44.920484Z","shell.execute_reply":"2023-06-02T14:20:44.926624Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['four children are playing on a trampoline.',\n 'Four kids are jumping on a trampoline.']"},"metadata":{}}]},{"cell_type":"code","source":"predict_sts(['Navin is brave.','Navin is strong.'])","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:22:11.277932Z","iopub.execute_input":"2023-06-02T14:22:11.278305Z","iopub.status.idle":"2023-06-02T14:22:11.727268Z","shell.execute_reply.started":"2023-06-02T14:22:11.278275Z","shell.execute_reply":"2023-06-02T14:22:11.726171Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.7044966220855713"},"metadata":{}}]},{"cell_type":"markdown","source":"## Export Model","metadata":{}},{"cell_type":"code","source":"state_dict = trained_model.state_dict()\n\n# Save the state dictionary to a file\ntorch.save(state_dict, \"model.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:26:45.059794Z","iopub.execute_input":"2023-06-02T14:26:45.060177Z","iopub.status.idle":"2023-06-02T14:26:45.557760Z","shell.execute_reply.started":"2023-06-02T14:26:45.060147Z","shell.execute_reply":"2023-06-02T14:26:45.556735Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# Export the function\nwith open(\"tokenzier.pkl\", \"wb\") as file:\n    pickle.dump(predict_sts, file)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:31:26.717752Z","iopub.execute_input":"2023-06-02T14:31:26.718622Z","iopub.status.idle":"2023-06-02T14:31:26.724119Z","shell.execute_reply.started":"2023-06-02T14:31:26.718586Z","shell.execute_reply":"2023-06-02T14:31:26.722752Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/predict_sts.pkl\", \"rb\") as file:\n\n    # Load the object from the file\n    fun = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:32:18.986847Z","iopub.execute_input":"2023-06-02T14:32:18.987231Z","iopub.status.idle":"2023-06-02T14:32:18.992533Z","shell.execute_reply.started":"2023-06-02T14:32:18.987204Z","shell.execute_reply":"2023-06-02T14:32:18.991468Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"fun(['My name is Navin','Tannu is my name'])","metadata":{"execution":{"iopub.status.busy":"2023-06-02T14:33:00.537142Z","iopub.execute_input":"2023-06-02T14:33:00.537493Z","iopub.status.idle":"2023-06-02T14:33:00.991619Z","shell.execute_reply.started":"2023-06-02T14:33:00.537465Z","shell.execute_reply":"2023-06-02T14:33:00.990688Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0.5924587249755859"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}